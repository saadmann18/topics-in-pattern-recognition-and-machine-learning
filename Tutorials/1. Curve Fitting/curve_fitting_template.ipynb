{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMR7f8DheAjP"
   },
   "source": [
    "# Curve fitting / Linear regression\n",
    "Remember: Linear does **not** mean linear in $x$ but linear in $w$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interactive, FloatSlider\n",
    "from IPython.display import display\n",
    "from numpy.polynomial.polynomial import polyvander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know what the command **%debug** do in ipython/jupyter?\n",
    "Type it in an empty cell and execute the cell when encounter an excpetion.\n",
    "\n",
    "Do you know what **Shift** + **Tab** does?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15Ti1mJteAjb"
   },
   "source": [
    "# Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKHxFbSReAjd"
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "sigma = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, num=5)\n",
    "M = 2\n",
    "X = ???\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GV3MYcS5fSc5"
   },
   "outputs": [],
   "source": [
    "def get_weight_vector(x, y, M):\n",
    "    # Your code here\n",
    "    ???\n",
    "    assert w.shape == (M+1,), w.shape\n",
    "    return ???\n",
    "\n",
    "def plot_result(order):\n",
    "    x_smooth = np.linspace(0, 1, 100)\n",
    "    y_smooth = np.sin(2*np.pi*x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, label='Ground truth', linestyle='--')\n",
    "    \n",
    "    x = np.linspace(0, 1, num=N)\n",
    "    y = np.sin(2*np.pi*x) + np.random.normal(0, sigma, size=N)\n",
    "    w = get_weight_vector(x, y, order)\n",
    "    plt.scatter(x, y, label='Train data')\n",
    "    \n",
    "    y_smooth_hat = polyvander(x_smooth, order) @ w\n",
    "    plt.plot(x_smooth, y_smooth_hat, label='Regression')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2esnrzIeAjj"
   },
   "outputs": [],
   "source": [
    "display(interactive(\n",
    "    plot_result,\n",
    "    order=IntSlider(min=0, max=???)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyaDhf7keAjm"
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpEha-0heAjp"
   },
   "source": [
    "# Task 1.3\n",
    "**Note**: The coefficients should still be calculated using the old number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1hoDUfQeAjt"
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(w, x, y):\n",
    "    \"\"\"Calculate and return RMSE\n",
    "    \"\"\"\n",
    "    return ???\n",
    "\n",
    "x_train = np.linspace(0, 1, num=N)\n",
    "y_train = np.sin(2 * np.pi * x_train) + np.random.normal(0, sigma, size=N)\n",
    "\n",
    "# 100 new test examples with x in [0, 1]\n",
    "x_test = ???\n",
    "y_test = ???\n",
    "\n",
    "# Calculate weight vectors for different Ms\n",
    "weight_vectors = [\n",
    "    get_weight_vector(x_train, y_train, M)\n",
    "    for M in range(???)\n",
    "]\n",
    "# Calculate rmse for M=0...10\n",
    "rmse = [calculate_rmse(w, x_train, y_train) for w in weight_vectors]\n",
    "plt.plot(rmse, label='RMSE Training')\n",
    "rmse = [calculate_rmse(w, x_test, y_test) for w in weight_vectors]\n",
    "plt.plot(rmse, label='RMSE Test')\n",
    "plt.legend()\n",
    "plt.xlabel('Order M')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7PIKisueAj2"
   },
   "source": [
    "# Task 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUKo6aZheAj3"
   },
   "source": [
    "**Additional notes**:\n",
    "- ``lambda`` is a reserved keyword in python (for an anonymous function) so please use another name for the variable\n",
    "- Can you now increase the polynomial order?\n",
    "- How does the regularization influence stability of the matrix inversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTZONjAOeAj3"
   },
   "outputs": [],
   "source": [
    "def get_weight_vector_regularized(x, y, M, lambda_):\n",
    "    # Your code here\n",
    "    return ???\n",
    "\n",
    "\n",
    "def plot_result(order, ln_lambda):\n",
    "    x_smooth = np.linspace(0, 1, 100)\n",
    "    y_smooth = np.sin(2*np.pi*x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, label='Ground truth', linestyle='--')\n",
    "    \n",
    "    x = np.linspace(0, 1, num=N)\n",
    "    y = np.sin(2*np.pi*x) + np.random.normal(0, sigma, size=N)\n",
    "    \n",
    "    w = get_weight_vector(x, y, order)\n",
    "    y_smooth_est = polyvander(x_smooth, order) @ w\n",
    "    plt.plot(x_smooth, y_smooth_est, label='Regression')\n",
    "    \n",
    "    w = get_weight_vector_regularized(x, y, order, np.exp(ln_lambda))\n",
    "    y_smooth_est = polyvander(x_smooth, order) @ w\n",
    "    plt.plot(x_smooth, y_smooth_est, label='Regression regularized')\n",
    "     \n",
    "    plt.scatter(x, y, label='Train data')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CR7AkhMHg8Lh"
   },
   "outputs": [],
   "source": [
    "display(interactive(\n",
    "    plot_result,\n",
    "    order=IntSlider(min=0, max=???)\n",
    "    ln_lambda=FloatSlider(min=???, max=???, step=???)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jauD7ugReAkC"
   },
   "source": [
    "# Task 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrquyKoleAkD"
   },
   "outputs": [],
   "source": [
    "M = ???\n",
    "ln_lmbda_values = ???\n",
    "\n",
    "x_train = np.linspace(0, 1, num=N)\n",
    "y_train = np.sin(2*np.pi*x_train) + np.random.normal(0, sigma, size=N)\n",
    "\n",
    "x_test = ???\n",
    "y_test = ???\n",
    "\n",
    "rmse_train = []\n",
    "rmse_test = []\n",
    "for ln_lmbda in ln_lmbda_values:\n",
    "    w = get_weight_vector_regularized(x_train, y_train, M, np.exp(ln_lmbda))\n",
    "    rmse_train.append(calculate_rmse(w, x_train, y_train))\n",
    "    rmse_test.append(calculate_rmse(w, x_test, y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ln_lmbda_values, rmse_train, label=f'RMSE train M={M}')\n",
    "plt.plot(ln_lmbda_values, rmse_test, label=f'RMSE test M={M}')\n",
    "plt.xlabel('$\\ln(\\lambda)$')\n",
    "\n",
    "w = get_weight_vector(x_train, y_train, M)\n",
    "rmse_train_wo_reg = calculate_rmse(w, x_train, y_train)\n",
    "rmse_test_wo_reg = calculate_rmse(w, x_test, y_test)\n",
    "\n",
    "plt.plot([min(ln_lmbda_values), max(ln_lmbda_values)],\n",
    "         [rmse_train_wo_reg, rmse_train_wo_reg],\n",
    "         label=f'RMSE train M={M}, lambda=0')\n",
    "plt.plot([min(ln_lmbda_values), max(ln_lmbda_values)],\n",
    "         [rmse_test_wo_reg, rmse_test_wo_reg],\n",
    "         label=f'RMSE test M={M}, lambda=0')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKefnsW_eAkS"
   },
   "source": [
    "# Task 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqeN5rPOeAkS"
   },
   "outputs": [],
   "source": [
    "def calc_mean_and_var(x, x_train, y_train, var_e, var_w, M):\n",
    "    \"\"\" Calculate the mean and variance of the predictive distribution\n",
    "    \n",
    "    :param x: Point for the prediction\n",
    "    :param x_train: Vector with training data points\n",
    "    :param Y_train: Vector with training targets\n",
    "    :param var_w: Variance for the prior of w\n",
    "    :param M: Order of the polynomial\n",
    "    \n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    ???\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuPJbLhFeAkW"
   },
   "outputs": [],
   "source": [
    "N = 30  # Number of training samples\n",
    "sigma = 0.18  # Variance of the observation noise\n",
    "sigma_w = 300*sigma  # Variance of the prior distribution for w\n",
    "M = 8  # Order of the model\n",
    "\n",
    "x_train = np.linspace(0, 1, num=N)\n",
    "y_train = np.sin(2*np.pi*x_train) + np.random.normal(0, sigma, size=N)\n",
    "mean = np.asarray([calc_mean_and_var(x, x_train, y_train, sigma, sigma_w, M)[0] for x in x_train])\n",
    "var = np.asarray([calc_mean_and_var(x, x_train, y_train, sigma, sigma_w, M)[1] for x in x_train])\n",
    "mean_line = plt.plot(x_train, mean, label='Mean')\n",
    "plt.plot(x_train, (mean - 2*np.sqrt(var)), color=mean_line[0].get_color(), linestyle='--', label='-2std')\n",
    "plt.plot(x_train, (mean + 2*np.sqrt(var)), color=mean_line[0].get_color(), linestyle='--', label='+2std')\n",
    "plt.scatter(x_train, y_train, label='Train data', color='g')\n",
    "plt.legend(loc=[1, 0.7])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "k0Lw53bWeAjb",
    "Lfyp9wPDfUIh",
    "lg8L4sOygcPV",
    "MIVdqMDWeAj0",
    "CdSjl2AOii5L",
    "J52uLO0weAkH",
    "EPk3Het_eAkM",
    "YlJFXJMaeAkO",
    "SvhDS-RXi3-q"
   ],
   "name": "ex1_curve_fitting_no_google.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
